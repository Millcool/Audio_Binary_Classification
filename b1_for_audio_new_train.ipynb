{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:09:46.171054Z",
     "iopub.status.busy": "2022-07-13T22:09:46.170371Z",
     "iopub.status.idle": "2022-07-13T22:09:49.059971Z",
     "shell.execute_reply": "2022-07-13T22:09:49.058765Z",
     "shell.execute_reply.started": "2022-07-13T22:09:46.170925Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79671\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\79671\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\79671\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from IPython import display as ipd\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder,  DatasetFolder,VisionDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import torchvision.models as models\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torchaudio\n",
    "#from pydub import AudioSegment\n",
    "from IPython import display\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    JUST_PREDICT  = False\n",
    "    Kaggle        = False \n",
    "    DEBUG         = True\n",
    "    FULL_DATA     = True\n",
    "    wandb_on      = False\n",
    "    seed          = 101\n",
    "    MULTIMODEL    = False\n",
    "    weights       = 'imagenet'\n",
    "    backbone      = 'efficientnet-b1'\n",
    "    model_name    = 'eff_net_b1'\n",
    "    archive_name  = 'Audio'\n",
    "    models        = []\n",
    "    optimizers    = []\n",
    "################################################### \n",
    "    num_of_models = 1\n",
    "    model_number  = 1\n",
    "    train_bs      = 32\n",
    "    valid_bs      = 32\n",
    "    width         = 1000 # image width\n",
    "    mels          = 80  # height\n",
    "    SAMPLE_RATE   = 16000\n",
    "    NUM_SAMPLES   = 48000\n",
    "    num_item_all  = 1000 if DEBUG else 120000      #611829\n",
    "    num_test      = 10 if DEBUG else 301      # 1000\n",
    "    print_every   = 1  if DEBUG else 50      #500\n",
    "    epochs        = 20  if DEBUG else 30        #35\n",
    "    ###############################################\n",
    "    crop_koef     = 1\n",
    "    lr            = 0.002\n",
    "    num_workers   = 4 if Kaggle else 0\n",
    "    criterion     = nn.CrossEntropyLoss()\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(30000/train_bs*epochs)+50\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    wd            = 1e-6\n",
    "    n_accumulate  = max(1, 32//train_bs)\n",
    "    n_fold        = 5\n",
    "    num_classes   = 2\n",
    "    classes       = [0,1]\n",
    "    activation    = None #'softmax'\n",
    "    device        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    test_path     = \"../input/russian-railways-2/test/test/\" if Kaggle else \"E:/Audio/ASV/clips/\"\n",
    "    save_path     = '../working/result/' if Kaggle else \"./result/\"\n",
    "    train_path    = \"E:/Audio/ASV/clips/\"\n",
    "    csv_path      = 'E:/Audio/ASV/valid' # '../../Испытание на стажировки/'\n",
    "    best_model_w  = '../input/russian-railways-2/best_epoch_ofu-efficientnet-b4_v2.bin' if Kaggle else f'./best_epoch_ofu-{backbone}_v2.bin'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Instalations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:09:49.069029Z",
     "iopub.status.busy": "2022-07-13T22:09:49.065209Z",
     "iopub.status.idle": "2022-07-13T22:09:49.171598Z",
     "shell.execute_reply": "2022-07-13T22:09:49.165850Z",
     "shell.execute_reply.started": "2022-07-13T22:09:49.068991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:09:49.214518Z",
     "iopub.status.busy": "2022-07-13T22:09:49.214144Z",
     "iopub.status.idle": "2022-07-13T22:09:49.225837Z",
     "shell.execute_reply": "2022-07-13T22:09:49.224029Z",
     "shell.execute_reply.started": "2022-07-13T22:09:49.214485Z"
    }
   },
   "outputs": [],
   "source": [
    "# Different classes dataset. \n",
    "classes = ('0','1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:09:49.227391Z",
     "iopub.status.busy": "2022-07-13T22:09:49.226911Z",
     "iopub.status.idle": "2022-07-13T22:09:49.245425Z",
     "shell.execute_reply": "2022-07-13T22:09:49.243813Z",
     "shell.execute_reply.started": "2022-07-13T22:09:49.227332Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(CFG.csv_path, sep = '\\t' ) #pd.read_csv(CFG.csv_path, sep = '\\\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF_E_2000011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF_E_2000013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DF_E_2000024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DF_E_2000026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF_E_2000027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DF_E_2000028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF_E_2000031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DF_E_2000032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DF_E_2000040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DF_E_2000042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF_E_2000044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF_E_2000048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DF_E_2000049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DF_E_2000053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DF_E_2000055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DF_E_2000058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DF_E_2000072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DF_E_2000075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DF_E_2000079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DF_E_2000080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF_E_2000091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF_E_2000096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DF_E_2000100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DF_E_2000102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DF_E_2000106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DF_E_2000115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DF_E_2000117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DF_E_2000123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DF_E_2000125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DF_E_2000126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DF_E_2000127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DF_E_2000128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DF_E_2000132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DF_E_2000137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DF_E_2000142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>DF_E_2000143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>DF_E_2000147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DF_E_2000151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DF_E_2000154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DF_E_2000160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DF_E_2000162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DF_E_2000165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DF_E_2000177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DF_E_2000179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DF_E_2000180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DF_E_2000182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>DF_E_2000183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>DF_E_2000193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>DF_E_2000199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>DF_E_2000200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            path  fake\n",
       "0   DF_E_2000011     1\n",
       "1   DF_E_2000013     1\n",
       "2   DF_E_2000024     1\n",
       "3   DF_E_2000026     1\n",
       "4   DF_E_2000027     1\n",
       "5   DF_E_2000028     1\n",
       "6   DF_E_2000031     1\n",
       "7   DF_E_2000032     1\n",
       "8   DF_E_2000040     1\n",
       "9   DF_E_2000042     1\n",
       "10  DF_E_2000044     1\n",
       "11  DF_E_2000048     1\n",
       "12  DF_E_2000049     1\n",
       "13  DF_E_2000053     0\n",
       "14  DF_E_2000055     1\n",
       "15  DF_E_2000058     0\n",
       "16  DF_E_2000072     1\n",
       "17  DF_E_2000075     1\n",
       "18  DF_E_2000079     0\n",
       "19  DF_E_2000080     1\n",
       "20  DF_E_2000091     1\n",
       "21  DF_E_2000096     1\n",
       "22  DF_E_2000100     1\n",
       "23  DF_E_2000102     1\n",
       "24  DF_E_2000106     1\n",
       "25  DF_E_2000115     1\n",
       "26  DF_E_2000117     1\n",
       "27  DF_E_2000123     1\n",
       "28  DF_E_2000125     1\n",
       "29  DF_E_2000126     1\n",
       "30  DF_E_2000127     1\n",
       "31  DF_E_2000128     1\n",
       "32  DF_E_2000132     1\n",
       "33  DF_E_2000137     1\n",
       "34  DF_E_2000142     1\n",
       "35  DF_E_2000143     1\n",
       "36  DF_E_2000147     1\n",
       "37  DF_E_2000151     1\n",
       "38  DF_E_2000154     1\n",
       "39  DF_E_2000160     1\n",
       "40  DF_E_2000162     1\n",
       "41  DF_E_2000165     1\n",
       "42  DF_E_2000177     1\n",
       "43  DF_E_2000179     1\n",
       "44  DF_E_2000180     1\n",
       "45  DF_E_2000182     1\n",
       "46  DF_E_2000183     1\n",
       "47  DF_E_2000193     1\n",
       "48  DF_E_2000199     1\n",
       "49  DF_E_2000200     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['path', 'fake'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(611829, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['fake'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchaudio.io import StreamReader\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_ids = list(data[1])\n",
    "# audio_names = list(data[0])\n",
    "# print(audio_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=CFG.SAMPLE_RATE,\n",
    "    n_fft=1024,\n",
    "    win_length = 1024,\n",
    "    hop_length=256,\n",
    "    n_mels= CFG.mels,\n",
    "    window_fn = torch.hann_window,\n",
    "    center=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanSoundDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 annotations_file,\n",
    "                 audio_dir,\n",
    "                 transformation,\n",
    "                 target_sample_rate,\n",
    "                 num_samples,\n",
    "                lable = False):\n",
    "        self.annotations = annotations_file\n",
    "        self.audio_dir = audio_dir\n",
    "        self.transformation = transformation\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.num_samples = num_samples\n",
    "        self.lable = lable\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_dir)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #print(index)\n",
    "        audio_sample_path = self._get_audio_sample_path(index)\n",
    "        signal, sr = torchaudio.load(audio_sample_path)\n",
    "        signal = self.transformation(signal)\n",
    "        #signal = self._resample_if_necessary(signal, sr)\n",
    "        signal = self._cut_if_necessary(signal)\n",
    "        signal = self._right_pad_if_necessary(signal)\n",
    "        signal = signal.repeat(3, 1, 1)\n",
    "        #signal = torch.squeeze(signal)\n",
    "        #signal = self.transformation(signal)\n",
    "        if self.lable == True: # WHEN WE TRAIN\n",
    "            label = self._get_audio_sample_label(index)\n",
    "            return signal, label\n",
    "        else: # WHEN WE PREDICT\n",
    "            return signal, torch.randint(0, 1, (1,))\n",
    "\n",
    "    def _cut_if_necessary(self, signal):\n",
    "        if signal.shape[2] > CFG.width:\n",
    "            signal = signal[:, :, 0:CFG.width]\n",
    "        return signal\n",
    "\n",
    "    def _right_pad_if_necessary(self, signal):\n",
    "        length_signal = signal.shape[2]\n",
    "        if length_signal < CFG.width:\n",
    "            num_missing_samples = CFG.width - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal\n",
    "\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "    def _get_audio_sample_path(self, index):\n",
    "        path = self.audio_dir[index]\n",
    "        if self.lable == True:\n",
    "            path = os.path.join(CFG.train_path,path)\n",
    "        else:\n",
    "            path = os.path.join(CFG.test_path,path)\n",
    "        path = path + '.flac'\n",
    "        return path\n",
    "\n",
    "    def _get_audio_sample_label(self, index):\n",
    "        path = self.audio_dir[index]\n",
    "        #print(path)\n",
    "        df = self.annotations\n",
    "        df = df.loc[lambda df: df['path'] == path]\n",
    "        #print(df.head())\n",
    "        #num = df['fake']\n",
    "        num = list(df['fake'])\n",
    "        #print(num)\n",
    "        return torch.Tensor(num)\n",
    "        #return num\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     ANNOTATIONS_FILE = \"/home/valerio/datasets/UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "#     AUDIO_DIR = \"/home/valerio/datasets/UrbanSound8K/audio\"\n",
    "#     SAMPLE_RATE = 22050\n",
    "#     NUM_SAMPLES = 22050\n",
    "\n",
    "#     mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "#         sample_rate=SAMPLE_RATE,\n",
    "#         n_fft=1024,\n",
    "#         hop_length=512,\n",
    "#         n_mels=64\n",
    "#     )\n",
    "\n",
    "#     usd = UrbanSoundDataset(ANNOTATIONS_FILE,\n",
    "#                             AUDIO_DIR,\n",
    "#                             mel_spectrogram,\n",
    "#                             SAMPLE_RATE,\n",
    "#                             NUM_SAMPLES)\n",
    "#     print(f\"There are {len(usd)} samples in the dataset.\")\n",
    "#     signal, label = usd[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clearing_names(audio_names : list, data) :\n",
    "#     for audio in enumerate(audio_names):\n",
    "#         if audio not in data:\n",
    "#             audio_names.remove(audio)\n",
    "#     return audio_names, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_names= [os.path.join(CFG.train_path,item_name) for item_name in os.listdir(CFG.train_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_names = []\n",
    "# bad_names = []\n",
    "# good_names = [try for item_name in audio_names]\n",
    "# for ind, name in enumerate(audio_names):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_names = []\n",
    "# bad_names = []\n",
    "# for ind, name in enumerate(audio_names):\n",
    "#     try:\n",
    "#         torchaudio.load(name)\n",
    "#         good_names.append(name)\n",
    "#         print(ind)\n",
    "#     except Exception:\n",
    "#         bad_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(good_names) , len(bad_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gn = good_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gn = [item_name.split('s/')[1] for item_name in gn ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gn = [item_name.split('.')[0] for item_name in gn ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'Names':gn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_names = pd.read_csv('./good_names',header=None, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_names = list(audio_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('good_names', index=False,header = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders():\n",
    "    audio_names = pd.read_csv(CFG.csv_path, sep = '\\t' )\n",
    "    audio_names = list(audio_names['path'])\n",
    "    #audio_names= [item_name.split('.')[0] for item_name in os.listdir(CFG.train_path)] #[os.path.join(\"./train/\",item_name)  for item_name in os.listdir(CFG.train_path)]\n",
    "    random.shuffle(audio_names)\n",
    "    audio_names = audio_names[:CFG.num_item_all]\n",
    "    print(f'Number of items we work with:{len(audio_names)}')\n",
    "    audio_train_valid, audio_test = train_test_split(audio_names, test_size=0.2 ,   random_state= CFG.seed)\n",
    "    audio_train, audio_valid = train_test_split(audio_train_valid, test_size=0.25 , random_state= CFG.seed)\n",
    "    #print(type(train_ids))\n",
    "    #print(valid_ids)\n",
    "    train_dataset = UrbanSoundDataset(data, audio_train, mel_spectrogram, CFG.SAMPLE_RATE, CFG.NUM_SAMPLES, True)\n",
    "    valid_dataset = UrbanSoundDataset(data, audio_valid, mel_spectrogram, CFG.SAMPLE_RATE, CFG.NUM_SAMPLES, True)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs, num_workers=0, shuffle=True, pin_memory=True, drop_last=False)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs, num_workers=0, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:09:49.253393Z",
     "iopub.status.busy": "2022-07-13T22:09:49.253083Z",
     "iopub.status.idle": "2022-07-13T22:09:49.294497Z",
     "shell.execute_reply": "2022-07-13T22:09:49.292752Z",
     "shell.execute_reply.started": "2022-07-13T22:09:49.253358Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Melspectrogram_visualize(array: torch.Tensor):\n",
    "    #print(array.shape)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.imshow(array.squeeze().log())\n",
    "    plt.xlabel('Time', size=20)\n",
    "    plt.ylabel('Frequency (Hz)', size=20)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "def visualize_audio(wav: torch.Tensor, sr: int = 22050):\n",
    "    # Average all channels\n",
    "    if wav.dim() == 2:\n",
    "        # Any to mono audio convertion\n",
    "        wav = wav.mean(dim=0)\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(wav, alpha=.7, c='green')\n",
    "    plt.grid()\n",
    "    plt.xlabel('Time', size=20)\n",
    "    plt.ylabel('Amplitude', size=20)\n",
    "    plt.show()\n",
    "    \n",
    "    display.display(display.Audio(wav, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List , Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items we work with:1000\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader = prepare_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 7)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader) , len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = next(iter(train_loader))\n",
    "#print(audio['wav'].shape)\n",
    "#print(Class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel = audio[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 80, 1000])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mels')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "#plt.imshow(mel.squeeze().log())\n",
    "plt.xlabel('Time', size=20)\n",
    "plt.ylabel('Mels', size=20)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Melspectrogram_visualize(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade efficientnet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_depth, depth, first=False):\n",
    "        super(ResNetBlock, self).__init__() # super(subclass) - we will inheritance fron superclass of subclass в данном случае можно было прсто написать super()\n",
    "        self.first = first\n",
    "        self.conv1 = nn.Conv2d(in_depth, depth, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(depth)\n",
    "        self.lrelu = nn.LeakyReLU(0.01)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.conv2 = nn.Conv2d(depth, depth, kernel_size=3, stride=3, padding=1)\n",
    "        self.conv11 = nn.Conv2d(in_depth, depth, kernel_size=3, stride=3, padding=1)\n",
    "        if not self.first :\n",
    "            self.pre_bn = nn.BatchNorm2d(in_depth)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is (B x d_in x T)\n",
    "        prev = x\n",
    "        prev_mp =  self.conv11(x)\n",
    "        if not self.first:\n",
    "            out = self.pre_bn(x)\n",
    "            out = self.lrelu(out)\n",
    "        else:\n",
    "            out = x\n",
    "        out = self.conv1(x)\n",
    "        # out is (B x depth x T/2)\n",
    "        out = self.bn1(out)\n",
    "        out = self.lrelu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        # out is (B x depth x T/2)\n",
    "        out = out + prev_mp\n",
    "        return out\n",
    "    \n",
    "class MFCCModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MFCCModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.block1 = ResNetBlock(32, 32,  True)\n",
    "        self.mp = nn.MaxPool2d(3, stride=3, padding=1)\n",
    "        self.block2 = ResNetBlock(32, 32,  False)\n",
    "        self.block3 = ResNetBlock(32, 32,  False)\n",
    "        self.block4= ResNetBlock(32, 32, False)\n",
    "        self.block5= ResNetBlock(32, 32, False)\n",
    "        self.block6 = ResNetBlock(32, 32, False)\n",
    "        self.block7 = ResNetBlock(32, 32, False)\n",
    "        self.block8 = ResNetBlock(32, 32, False)\n",
    "        self.block9 = ResNetBlock(32, 32, False)\n",
    "        self.lrelu = nn.LeakyReLU(0.01)\n",
    "        self.bn = nn.BatchNorm2d(32)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        self.fc1 = nn.Linear(32, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.unsqueeze(dim=1)\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.mp(out)\n",
    "        out = self.block4(out)\n",
    "        out = self.block5(out)\n",
    "        out = self.block6(out)\n",
    "        out = self.mp(out)\n",
    "        out = self.block7(out)\n",
    "        out = self.block8(out)\n",
    "        out = self.block9(out)\n",
    "        out = self.bn(out)\n",
    "        out = self.lrelu(out)\n",
    "        out = self.mp(out)\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.lrelu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.logsoftmax(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    }
   ],
   "source": [
    "device = CFG.device\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "model_name = 'efficientnet-b1'\n",
    "model = EfficientNet.from_pretrained(model_name).to(device)  #, num_classes=3\n",
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False \n",
    "    \n",
    "    \n",
    "model._fc = torch.nn.Sequential(\n",
    "    nn.Linear(in_features=1280, out_features=625, bias=True),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Linear(in_features=625, out_features=256, bias=True),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=256, out_features=2, bias=True))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "#model = MFCCModel().to(device)\n",
    "#featurizer = Featurizer().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model._fc.parameters(), lr=0.003)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC DIR CREATED\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "\n",
    "try:\n",
    "    if CFG.Kaggle:\n",
    "        os.mkdir('../working/result')\n",
    "        print('KAGGLE DIR CREATED')\n",
    "    else:\n",
    "        #shutil.rmtree('./result')\n",
    "        local_time = time.ctime().replace(' ', '_').replace(':', '.')\n",
    "        directory = f'./result_{CFG.model_name}_{local_time}'\n",
    "        os.mkdir(directory)\n",
    "        print('PC DIR CREATED')\n",
    "except Exception:\n",
    "    print(\"DIR NOT CREATED\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_det_curve(target_scores, nontarget_scores):\n",
    "\n",
    "    n_scores = target_scores.size + nontarget_scores.size # sum of sizes \n",
    "    all_scores = np.concatenate((target_scores, nontarget_scores)) # vector of scores\n",
    "    labels = np.concatenate((np.ones(target_scores.size), np.zeros(nontarget_scores.size))) # vextor of labels\n",
    "    # Sort labels based on scores\n",
    "    indices = np.argsort(all_scores, kind='mergesort') # retern indexes of sorted array of zeros and ones\n",
    "    labels = labels[indices] # and sort labels like (zeros and ones) for all 0 in both arrays and (zeros + ones) of 1 in both arrays\n",
    "\n",
    "    # Compute false rejection and false acceptance rates\n",
    "    tar_trial_sums = np.cumsum(labels) # array with max element N\n",
    "    # (np.arange(1, n_scores + 1, step = 1) - tar_trial_sums | gives array of element with max el = N\n",
    "    nontarget_trial_sums = nontarget_scores.size - (np.arange(1, n_scores + 1, step = 1) - tar_trial_sums)\n",
    "\n",
    "    frr = np.concatenate((np.atleast_1d(0), tar_trial_sums / target_scores.size))  # false rejection rates\n",
    "    far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums / nontarget_scores.size))  # false acceptance rates\n",
    "    thresholds = np.concatenate((np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))  # Thresholds are the sorted scores\n",
    "\n",
    "    return frr, far, thresholds\n",
    "def compute_eer(target_scores, nontarget_scores):\n",
    "    \"\"\" Returns equal error rate (EER) and the corresponding threshold. \"\"\"\n",
    "    frr, far, thresholds = compute_det_curve(target_scores, nontarget_scores)\n",
    "    abs_diffs = np.abs(frr - far)\n",
    "    min_index = np.argmin(abs_diffs) # return index of min element\n",
    "    eer = np.mean((frr[min_index], far[min_index]))\n",
    "    return eer, thresholds[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    data_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    return_losses=False,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    model = model.to(device).train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    all_losses = []\n",
    "    total_predictions = np.array([])#.reshape((0, ))\n",
    "    total_labels = np.array([])#.reshape((0, ))\n",
    "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
    "        for images, labels in data_loader:\n",
    "            # Move Batch to GPU\n",
    "            images = images.to(device)\n",
    "            labels = labels.reshape(len(labels))\n",
    "            labels = labels.to(device)\n",
    "            predicted = model(images)\n",
    "            loss = criterion(predicted, labels)\n",
    "            # Update weights\n",
    "            loss.backward()\n",
    "            optimizer.step() #step - обновление весов модели\n",
    "            optimizer.zero_grad() #zero_grad - занулить веса модели (по умолчанию градиенты в PyTorch аккумулируются) ~ for each param in params: param.grad = None\n",
    "            # Update descirption for tqdm\n",
    "            accuracy = (predicted.argmax(1) == labels).float().mean()\n",
    "            prbar.set_description( \n",
    "                f\"Loss: {round(loss.item(), 4)} \" # .item - from tensor to python number\n",
    "                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n",
    "            )\n",
    "            prbar.update(1)\n",
    "            total_loss += loss.item()\n",
    "            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n",
    "            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
    "            num_batches += 1\n",
    "            all_losses.append(loss.detach().item())\n",
    "    metrics = {\"loss\": total_loss / num_batches}\n",
    "    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n",
    "    if return_losses:\n",
    "        return metrics, all_losses\n",
    "    else:\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def validate(model, data_loader, criterion, device=\"cuda\"):\n",
    "    model = model.eval() # выключает некоторые слои при подсчете\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    total_predictions = np.array([])\n",
    "    total_labels = np.array([])\n",
    "    with tqdm(total=len(data_loader), file=sys.stdout, unit = \"batch\") as prbar: # pregress bar\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.reshape(len(labels))\n",
    "            labels = labels.to(device)\n",
    "            predicted = model(images)\n",
    "            loss = criterion(predicted, labels)\n",
    "            accuracy = (predicted.argmax(1) == labels).float().mean()\n",
    "            prbar.set_description(\n",
    "                f\"Loss: {round(loss.item(), 4)} \"\n",
    "                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n",
    "            )\n",
    "            prbar.update(1)\n",
    "            total_loss += loss.item()\n",
    "            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n",
    "            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
    "            num_batches += 1\n",
    "    metrics = {\"loss\": total_loss / num_batches}\n",
    "    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model,\n",
    "    epochs,\n",
    "    train_data_loader,\n",
    "    validation_data_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    all_train_losses = []\n",
    "    epoch_train_losses = []\n",
    "    epoch_eval_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        # Train step\n",
    "        print(f\"Train Epoch: {epoch}\")\n",
    "        train_metrics, one_epoch_train_losses = train_epoch(\n",
    "            model=model,\n",
    "            data_loader=train_data_loader,\n",
    "            optimizer=optimizer,\n",
    "            return_losses=True,\n",
    "            criterion=criterion,\n",
    "            device=device\n",
    "        )\n",
    "        # Save Train losses\n",
    "        all_train_losses.extend(one_epoch_train_losses) # добавляет в конец списка как отдельные элементы\n",
    "        epoch_train_losses.append(train_metrics[\"loss\"]) # добавляет в конец список как список\n",
    "        # Eval step\n",
    "        print(f\"Validation Epoch: {epoch}\")\n",
    "        with torch.no_grad():\n",
    "            validation_metrics = validate(\n",
    "                model=model,\n",
    "                data_loader=validation_data_loader,\n",
    "                criterion=criterion\n",
    "            )\n",
    "        # Save eval losses\n",
    "        epoch_eval_losses.append(validation_metrics[\"loss\"]) # добавляет в конец список как список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9204d6959394932b7711ddb912ea78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(model, epochs, train_data_loader, validation_data_loader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Train step\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m     train_metrics, one_epoch_train_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_losses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Save Train losses\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     all_train_losses\u001b[38;5;241m.\u001b[39mextend(one_epoch_train_losses) \u001b[38;5;66;03m# добавляет в конец списка как отдельные элементы\u001b[39;00m\n",
      "Input \u001b[1;32mIn [48]\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, data_loader, optimizer, criterion, return_losses, device)\u001b[0m\n\u001b[0;32m     20\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m predicted \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m---> 22\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[0;32m     24\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1163\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2996\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   2994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2995\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 2996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'"
     ]
    }
   ],
   "source": [
    "fit(model, CFG.epochs , train_loader, valid_loader, optimizer, criterion, device=CFG.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "PATH = f\"./result/Last_epoch_of_{CFG.model_name}.bin\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrix = [[0,0],[0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrix+=matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage['validation_F1_score']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(out.cpu(),label.cpu(),average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:11:13.108463Z",
     "iopub.status.busy": "2022-07-13T22:11:13.107767Z",
     "iopub.status.idle": "2022-07-13T22:27:41.170460Z",
     "shell.execute_reply": "2022-07-13T22:27:41.169446Z",
     "shell.execute_reply.started": "2022-07-13T22:11:13.108421Z"
    }
   },
   "outputs": [],
   "source": [
    "#fit(model, CFG.epochs , train_loader, valid_loader, optimizer, CFG.criterion, CFG.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficcient_net predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:27:41.922371Z",
     "iopub.status.busy": "2022-07-13T22:27:41.921713Z",
     "iopub.status.idle": "2022-07-13T22:27:45.531639Z",
     "shell.execute_reply": "2022-07-13T22:27:45.530687Z",
     "shell.execute_reply.started": "2022-07-13T22:27:41.922318Z"
    }
   },
   "outputs": [],
   "source": [
    "#test = []\n",
    "'./test/'\n",
    "items_names= [item_name.split('.')[0] for item_name in os.listdir(CFG.test_path)]#os.path.join(\"./test\",item_name)\n",
    "test_dataset = UrbanSoundDataset(data, items_names, mel_spectrogram, CFG.SAMPLE_RATE, CFG.NUM_SAMPLES, False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, num_workers=0, shuffle=False, pin_memory=True, drop_last=False,collate_fn=Collator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i, batch in enumerate(tqdm(test_loader)):\n",
    "        # Move batch to device if device != 'cpu'\n",
    "        wav = batch['wav'].to(device)\n",
    "        length = batch['length'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            mel, mel_length = featurizer(wav, length)\n",
    "            output = model(mel, mel_length)\n",
    "            #print(output)\n",
    "            _, pred = torch.max(output, 1) # Return values and indices\n",
    "            #m = nn.Softmax(dim=1)\n",
    "            #pred = m(output)\n",
    "            #print(pred)\n",
    "            #print(pred.item())\n",
    "            #df\n",
    "            test.append(classes[pred.item()])\n",
    "#print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_names= [item_name.split('.')[0] for item_name in os.listdir(CFG.test_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:29:38.581683Z",
     "iopub.status.busy": "2022-07-13T22:29:38.581326Z",
     "iopub.status.idle": "2022-07-13T22:29:38.588448Z",
     "shell.execute_reply": "2022-07-13T22:29:38.585882Z",
     "shell.execute_reply.started": "2022-07-13T22:29:38.581655Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"id\" :items_names,\n",
    "                   \"eff\": test\n",
    "        \n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.747598Z",
     "iopub.status.idle": "2022-07-13T22:27:45.748300Z",
     "shell.execute_reply": "2022-07-13T22:27:45.748059Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.748035Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ansamble_pred = df['eff'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generating submission file...')\n",
    "#os.chdir(\"./\")\n",
    "df.to_csv('answers.tsv',index=False, sep = '\\t',header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.749586Z",
     "iopub.status.idle": "2022-07-13T22:27:45.750270Z",
     "shell.execute_reply": "2022-07-13T22:27:45.750041Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.750017Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\"id\" : range(1,250),\n",
    "#                    \"class\": ansamble_pred\n",
    "# #                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.751572Z",
     "iopub.status.idle": "2022-07-13T22:27:45.752256Z",
     "shell.execute_reply": "2022-07-13T22:27:45.752029Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.752006Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\"id\" : range(1,250),\n",
    "#                    \"class\": test\n",
    "#                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.754037Z",
     "iopub.status.idle": "2022-07-13T22:27:45.754749Z",
     "shell.execute_reply": "2022-07-13T22:27:45.754517Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.754493Z"
    }
   },
   "outputs": [],
   "source": [
    "# df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.756008Z",
     "iopub.status.idle": "2022-07-13T22:27:45.756719Z",
     "shell.execute_reply": "2022-07-13T22:27:45.756489Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.756465Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.757997Z",
     "iopub.status.idle": "2022-07-13T22:27:45.758717Z",
     "shell.execute_reply": "2022-07-13T22:27:45.758484Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.758460Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_full.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.760001Z",
     "iopub.status.idle": "2022-07-13T22:27:45.760725Z",
     "shell.execute_reply": "2022-07-13T22:27:45.760495Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.760471Z"
    }
   },
   "outputs": [],
   "source": [
    "# print('Generating submission file...')\n",
    "#os.chdir(\"./\")\n",
    "# df.to_csv('submission_audio.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.761988Z",
     "iopub.status.idle": "2022-07-13T22:27:45.762720Z",
     "shell.execute_reply": "2022-07-13T22:27:45.762480Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.762456Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_full.to_csv('submission_effnet7new2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
