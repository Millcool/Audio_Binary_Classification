{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:09:46.171054Z",
     "iopub.status.busy": "2022-07-13T22:09:46.170371Z",
     "iopub.status.idle": "2022-07-13T22:09:49.059971Z",
     "shell.execute_reply": "2022-07-13T22:09:49.058765Z",
     "shell.execute_reply.started": "2022-07-13T22:09:46.170925Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79671\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\79671\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\79671\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "from IPython import display as ipd\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder,  DatasetFolder,VisionDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import torchvision.models as models\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torchaudio\n",
    "#from pydub import AudioSegment\n",
    "from IPython import display\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    JUST_PREDICT  = False\n",
    "    Kaggle        = False \n",
    "    DEBUG         = False\n",
    "    FULL_DATA     = True\n",
    "    wandb_on      = False\n",
    "    seed          = 101\n",
    "    MULTIMODEL    = False\n",
    "    weights       = 'imagenet'\n",
    "    backbone      = 'efficientnet-b1'\n",
    "    archive_name  = 'Audio'\n",
    "    models        = []\n",
    "    optimizers    = []\n",
    "################################################### \n",
    "    num_of_models = 1\n",
    "    model_number  = 1\n",
    "    train_bs      = 32\n",
    "    valid_bs      = 32\n",
    "    width         = 100\n",
    "    SAMPLE_RATE   = 16000\n",
    "    NUM_SAMPLES   = 48000\n",
    "    num_item_all  = 10 if DEBUG else 611800      #611829\n",
    "    num_test      = 10 if DEBUG else 301      # 1000\n",
    "    print_every   = 1  if DEBUG else 50      #500\n",
    "    epochs        = 2  if DEBUG else 30        #35\n",
    "    ###############################################\n",
    "    crop_koef     = 1\n",
    "    lr            = 0.002\n",
    "    num_workers   = 4 if Kaggle else 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(30000/train_bs*epochs)+50\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    wd            = 1e-6\n",
    "    n_accumulate  = max(1, 32//train_bs)\n",
    "    n_fold        = 5\n",
    "    num_classes   = 2\n",
    "    classes       = [0,1]\n",
    "    activation    = None #'softmax'\n",
    "    device        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    test_path     = \"../input/russian-railways-2/test/test/\" if Kaggle else \"E:/Audio/ASV/clips/\"\n",
    "    save_path     = '../working/result/' if Kaggle else \"./result/\"\n",
    "    train_path    = \"E:/Audio/ASV/clips/\"\n",
    "    csv_path      = 'E:/Audio/ASV/valid' # '../../Испытание на стажировки/'\n",
    "    best_model_w  = '../input/russian-railways-2/best_epoch_ofu-efficientnet-b4_v2.bin' if Kaggle else f'./best_epoch_ofu-{backbone}_v2.bin'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Instalations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:09:49.069029Z",
     "iopub.status.busy": "2022-07-13T22:09:49.065209Z",
     "iopub.status.idle": "2022-07-13T22:09:49.171598Z",
     "shell.execute_reply": "2022-07-13T22:09:49.165850Z",
     "shell.execute_reply.started": "2022-07-13T22:09:49.068991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#waveform, sample_rate = torchaudio.load('./train/000ad36ce0dcbc1032a606312d5e787d.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display.Audio(waveform, rate = sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#waveform.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mel_Spectrogram = torchaudio.transforms.MelSpectrogram()(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mel_Spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install PySoundFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:09:49.214518Z",
     "iopub.status.busy": "2022-07-13T22:09:49.214144Z",
     "iopub.status.idle": "2022-07-13T22:09:49.225837Z",
     "shell.execute_reply": "2022-07-13T22:09:49.224029Z",
     "shell.execute_reply.started": "2022-07-13T22:09:49.214485Z"
    }
   },
   "outputs": [],
   "source": [
    "# Different classes dataset. \n",
    "classes = ('0','1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:09:49.227391Z",
     "iopub.status.busy": "2022-07-13T22:09:49.226911Z",
     "iopub.status.idle": "2022-07-13T22:09:49.245425Z",
     "shell.execute_reply": "2022-07-13T22:09:49.243813Z",
     "shell.execute_reply.started": "2022-07-13T22:09:49.227332Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(CFG.csv_path, sep = '\\t' ) #pd.read_csv(CFG.csv_path, sep = '\\\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.rename(columns={0: \"Name\", 1: \"Target\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.concat([data['path'] , data['fake']] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF_E_2000011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF_E_2000013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DF_E_2000024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DF_E_2000026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF_E_2000027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DF_E_2000028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF_E_2000031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DF_E_2000032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DF_E_2000040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DF_E_2000042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF_E_2000044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF_E_2000048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DF_E_2000049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DF_E_2000053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DF_E_2000055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DF_E_2000058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DF_E_2000072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DF_E_2000075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DF_E_2000079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DF_E_2000080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF_E_2000091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF_E_2000096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DF_E_2000100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DF_E_2000102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DF_E_2000106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DF_E_2000115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DF_E_2000117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DF_E_2000123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DF_E_2000125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DF_E_2000126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DF_E_2000127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DF_E_2000128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DF_E_2000132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DF_E_2000137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DF_E_2000142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>DF_E_2000143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>DF_E_2000147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DF_E_2000151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DF_E_2000154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DF_E_2000160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DF_E_2000162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DF_E_2000165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DF_E_2000177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DF_E_2000179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DF_E_2000180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DF_E_2000182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>DF_E_2000183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>DF_E_2000193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>DF_E_2000199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>DF_E_2000200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            path  fake\n",
       "0   DF_E_2000011     1\n",
       "1   DF_E_2000013     1\n",
       "2   DF_E_2000024     1\n",
       "3   DF_E_2000026     1\n",
       "4   DF_E_2000027     1\n",
       "5   DF_E_2000028     1\n",
       "6   DF_E_2000031     1\n",
       "7   DF_E_2000032     1\n",
       "8   DF_E_2000040     1\n",
       "9   DF_E_2000042     1\n",
       "10  DF_E_2000044     1\n",
       "11  DF_E_2000048     1\n",
       "12  DF_E_2000049     1\n",
       "13  DF_E_2000053     0\n",
       "14  DF_E_2000055     1\n",
       "15  DF_E_2000058     0\n",
       "16  DF_E_2000072     1\n",
       "17  DF_E_2000075     1\n",
       "18  DF_E_2000079     0\n",
       "19  DF_E_2000080     1\n",
       "20  DF_E_2000091     1\n",
       "21  DF_E_2000096     1\n",
       "22  DF_E_2000100     1\n",
       "23  DF_E_2000102     1\n",
       "24  DF_E_2000106     1\n",
       "25  DF_E_2000115     1\n",
       "26  DF_E_2000117     1\n",
       "27  DF_E_2000123     1\n",
       "28  DF_E_2000125     1\n",
       "29  DF_E_2000126     1\n",
       "30  DF_E_2000127     1\n",
       "31  DF_E_2000128     1\n",
       "32  DF_E_2000132     1\n",
       "33  DF_E_2000137     1\n",
       "34  DF_E_2000142     1\n",
       "35  DF_E_2000143     1\n",
       "36  DF_E_2000147     1\n",
       "37  DF_E_2000151     1\n",
       "38  DF_E_2000154     1\n",
       "39  DF_E_2000160     1\n",
       "40  DF_E_2000162     1\n",
       "41  DF_E_2000165     1\n",
       "42  DF_E_2000177     1\n",
       "43  DF_E_2000179     1\n",
       "44  DF_E_2000180     1\n",
       "45  DF_E_2000182     1\n",
       "46  DF_E_2000183     1\n",
       "47  DF_E_2000193     1\n",
       "48  DF_E_2000199     1\n",
       "49  DF_E_2000200     1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['path', 'fake'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(611829, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['fake'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchaudio.io import StreamReader\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_ids = list(data[1])\n",
    "# audio_names = list(data[0])\n",
    "# print(audio_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=22050,\n",
    "    n_fft=1024,\n",
    "    win_length = 1024,\n",
    "    hop_length=256,\n",
    "    n_mels=80,\n",
    "    window_fn = torch.hann_window,\n",
    "    center=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanSoundDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 annotations_file,\n",
    "                 audio_dir,\n",
    "                 transformation,\n",
    "                 target_sample_rate,\n",
    "                 num_samples,\n",
    "                lable = False):\n",
    "        self.annotations = annotations_file\n",
    "        self.audio_dir = audio_dir\n",
    "        self.transformation = transformation\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.num_samples = num_samples\n",
    "        self.lable = lable\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_dir)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #print(index)\n",
    "        audio_sample_path = self._get_audio_sample_path(index)\n",
    "        signal, sr = torchaudio.load(audio_sample_path)\n",
    "        signal = self.transformation(signal)\n",
    "        #signal = signal[:, :, 0:CFG.width]\n",
    "        #signal = self._resample_if_necessary(signal, sr)\n",
    "        signal = self._cut_if_necessary(signal)\n",
    "        signal = self._right_pad_if_necessary(signal)\n",
    "        signal = signal.repeat(3, 1, 1)\n",
    "        #signal = torch.squeeze(signal)\n",
    "        #signal = self.transformation(signal)\n",
    "        if self.lable == True: # WHEN WE TRAIN\n",
    "            label = self._get_audio_sample_label(index)\n",
    "            return signal, label\n",
    "        else: # WHEN WE PREDICT\n",
    "            return signal, torch.randint(0, 1, (1,))\n",
    "\n",
    "    def _cut_if_necessary(self, signal):\n",
    "        if signal.shape[2] > CFG.width:\n",
    "            signal = signal[:, :, 0:CFG.width]\n",
    "        return signal\n",
    "\n",
    "    def _right_pad_if_necessary(self, signal):\n",
    "        length_signal = signal.shape[2]\n",
    "        if length_signal < CFG.width:\n",
    "            num_missing_samples = CFG.width - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal\n",
    "\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "    def _get_audio_sample_path(self, index):\n",
    "        path = self.audio_dir[index]\n",
    "        if self.lable == True:\n",
    "            path = os.path.join(CFG.train_path,path)\n",
    "        else:\n",
    "            path = os.path.join(CFG.test_path,path)\n",
    "        path = path + '.flac'\n",
    "        return path\n",
    "\n",
    "    def _get_audio_sample_label(self, index):\n",
    "        path = self.audio_dir[index]\n",
    "        #print(path)\n",
    "        df = self.annotations\n",
    "        df = df.loc[lambda df: df['path'] == path]\n",
    "        #print(df.head())\n",
    "        num = list(df['fake'])\n",
    "        #print(num)\n",
    "        return torch.Tensor(num)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     ANNOTATIONS_FILE = \"/home/valerio/datasets/UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "#     AUDIO_DIR = \"/home/valerio/datasets/UrbanSound8K/audio\"\n",
    "#     SAMPLE_RATE = 22050\n",
    "#     NUM_SAMPLES = 22050\n",
    "\n",
    "#     mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "#         sample_rate=SAMPLE_RATE,\n",
    "#         n_fft=1024,\n",
    "#         hop_length=512,\n",
    "#         n_mels=64\n",
    "#     )\n",
    "\n",
    "#     usd = UrbanSoundDataset(ANNOTATIONS_FILE,\n",
    "#                             AUDIO_DIR,\n",
    "#                             mel_spectrogram,\n",
    "#                             SAMPLE_RATE,\n",
    "#                             NUM_SAMPLES)\n",
    "#     print(f\"There are {len(usd)} samples in the dataset.\")\n",
    "#     signal, label = usd[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clearing_names(audio_names : list, data) :\n",
    "#     for audio in enumerate(audio_names):\n",
    "#         if audio not in data:\n",
    "#             audio_names.remove(audio)\n",
    "#     return audio_names, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_names= [os.path.join(CFG.train_path,item_name) for item_name in os.listdir(CFG.train_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_names = []\n",
    "# bad_names = []\n",
    "# good_names = [try for item_name in audio_names]\n",
    "# for ind, name in enumerate(audio_names):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_names = []\n",
    "# bad_names = []\n",
    "# for ind, name in enumerate(audio_names):\n",
    "#     try:\n",
    "#         torchaudio.load(name)\n",
    "#         good_names.append(name)\n",
    "#         print(ind)\n",
    "#     except Exception:\n",
    "#         bad_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(good_names) , len(bad_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gn = good_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gn = [item_name.split('s/')[1] for item_name in gn ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gn = [item_name.split('.')[0] for item_name in gn ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'Names':gn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_names = pd.read_csv('./good_names',header=None, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_names = list(audio_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('good_names', index=False,header = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders():\n",
    "    audio_names = pd.read_csv(CFG.csv_path, sep = '\\t' )\n",
    "    audio_names = list(audio_names['path'])\n",
    "    #audio_names= [item_name.split('.')[0] for item_name in os.listdir(CFG.train_path)] #[os.path.join(\"./train/\",item_name)  for item_name in os.listdir(CFG.train_path)]\n",
    "    random.shuffle(audio_names)\n",
    "    audio_names = audio_names[:CFG.num_item_all]\n",
    "    print(len(audio_names))\n",
    "    audio_train_valid, audio_test = train_test_split(audio_names, test_size=0.2 , random_state=42)\n",
    "    audio_train, audio_valid = train_test_split(audio_train_valid, test_size=0.25 , random_state=42)\n",
    "    #print(type(train_ids))\n",
    "    #print(valid_ids)\n",
    "    train_dataset = UrbanSoundDataset(data, audio_train, mel_spectrogram, CFG.SAMPLE_RATE, CFG.NUM_SAMPLES, True)\n",
    "    valid_dataset = UrbanSoundDataset(data, audio_valid, mel_spectrogram, CFG.SAMPLE_RATE, CFG.NUM_SAMPLES, True)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs, num_workers=0, shuffle=True, pin_memory=True, drop_last=False)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs, num_workers=0, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:09:49.253393Z",
     "iopub.status.busy": "2022-07-13T22:09:49.253083Z",
     "iopub.status.idle": "2022-07-13T22:09:49.294497Z",
     "shell.execute_reply": "2022-07-13T22:09:49.292752Z",
     "shell.execute_reply.started": "2022-07-13T22:09:49.253358Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# transformations = transforms.Compose(\n",
    "#     ProcessChannels(mode=avg)\n",
    "#     AdditiveNoise(prob=0.3, sig=0.001, dist_type=normal)\n",
    "#     RandomCropLength(prob=0.4, sig=0.25, dist_type=half)\n",
    "#     ToTensorAudio()\n",
    "# )\n",
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=CFG.SAMPLE_RATE,\n",
    "    n_fft=1024,\n",
    "    win_length = 1024,\n",
    "    hop_length=256,\n",
    "    n_mels=80,\n",
    "    window_fn = torch.hann_window,\n",
    "    center=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Melspectrogram_visualize(array: torch.Tensor):\n",
    "    #print(array.shape)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.imshow(array.squeeze().log())\n",
    "    plt.xlabel('Time', size=20)\n",
    "    plt.ylabel('Frequency (Hz)', size=20)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "def visualize_audio(wav: torch.Tensor, sr: int = 22050):\n",
    "    # Average all channels\n",
    "    if wav.dim() == 2:\n",
    "        # Any to mono audio convertion\n",
    "        wav = wav.mean(dim=0)\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(wav, alpha=.7, c='green')\n",
    "    plt.grid()\n",
    "    plt.xlabel('Time', size=20)\n",
    "    plt.ylabel('Amplitude', size=20)\n",
    "    plt.show()\n",
    "    \n",
    "    display.display(display.Audio(wav, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List , Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611800\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader = prepare_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11472, 3824)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader) , len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = next(iter(train_loader))\n",
    "#print(audio['wav'].shape)\n",
    "#print(Class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel = audio[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 80, 100])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mels')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "#plt.imshow(mel.squeeze().log())\n",
    "plt.xlabel('Time', size=20)\n",
    "plt.ylabel('Mels', size=20)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Melspectrogram_visualize(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade efficientnet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        16, 16, kernel_size=(3, 3), stride=(1, 1), groups=16, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        16, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 16, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        320, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1920, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1920, 1920, kernel_size=(3, 3), stride=(1, 1), groups=1920, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1920, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1920, 80, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        80, 1920, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1920, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model_name = 'efficientnet-b1'\n",
    "model = EfficientNet.from_pretrained(model_name)  #, num_classes=3\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_depth, depth, first=False):\n",
    "        super(ResNetBlock, self).__init__() # super(subclass) - we will inheritance fron superclass of subclass в данном случае можно было прсто написать super()\n",
    "        self.first = first\n",
    "        self.conv1 = nn.Conv2d(in_depth, depth, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(depth)\n",
    "        self.lrelu = nn.LeakyReLU(0.01)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.conv2 = nn.Conv2d(depth, depth, kernel_size=3, stride=3, padding=1)\n",
    "        self.conv11 = nn.Conv2d(in_depth, depth, kernel_size=3, stride=3, padding=1)\n",
    "        if not self.first :\n",
    "            self.pre_bn = nn.BatchNorm2d(in_depth)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is (B x d_in x T)\n",
    "        prev = x\n",
    "        prev_mp =  self.conv11(x)\n",
    "        if not self.first:\n",
    "            out = self.pre_bn(x)\n",
    "            out = self.lrelu(out)\n",
    "        else:\n",
    "            out = x\n",
    "        out = self.conv1(x)\n",
    "        # out is (B x depth x T/2)\n",
    "        out = self.bn1(out)\n",
    "        out = self.lrelu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        # out is (B x depth x T/2)\n",
    "        out = out + prev_mp\n",
    "        return out\n",
    "    \n",
    "class MFCCModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MFCCModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.block1 = ResNetBlock(32, 32,  True)\n",
    "        self.mp = nn.MaxPool2d(3, stride=3, padding=1)\n",
    "        self.block2 = ResNetBlock(32, 32,  False)\n",
    "        self.block3 = ResNetBlock(32, 32,  False)\n",
    "        self.block4= ResNetBlock(32, 32, False)\n",
    "        self.block5= ResNetBlock(32, 32, False)\n",
    "        self.block6 = ResNetBlock(32, 32, False)\n",
    "        self.block7 = ResNetBlock(32, 32, False)\n",
    "        self.block8 = ResNetBlock(32, 32, False)\n",
    "        self.block9 = ResNetBlock(32, 32, False)\n",
    "        self.lrelu = nn.LeakyReLU(0.01)\n",
    "        self.bn = nn.BatchNorm2d(32)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        self.fc1 = nn.Linear(32, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.unsqueeze(dim=1)\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.mp(out)\n",
    "        out = self.block4(out)\n",
    "        out = self.block5(out)\n",
    "        out = self.block6(out)\n",
    "        out = self.mp(out)\n",
    "        out = self.block7(out)\n",
    "        out = self.block8(out)\n",
    "        out = self.block9(out)\n",
    "        out = self.bn(out)\n",
    "        out = self.lrelu(out)\n",
    "        out = self.mp(out)\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.lrelu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.logsoftmax(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    }
   ],
   "source": [
    "device = CFG.device\n",
    "\n",
    "model = EfficientNet.from_pretrained(model_name).to(device)  #, num_classes=3\n",
    "#model = MFCCModel().to(device)\n",
    "#featurizer = Featurizer().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC DIR CREATED\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "\n",
    "try:\n",
    "    if CFG.Kaggle:\n",
    "        os.mkdir('../working/result')\n",
    "        print('KAGGLE DIR CREATED')\n",
    "    else:\n",
    "        shutil.rmtree('./result')\n",
    "        os.mkdir('./result')\n",
    "        print('PC DIR CREATED')\n",
    "except Exception:\n",
    "    print(\"DIR NOT CREATED\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_det_curve(target_scores, nontarget_scores):\n",
    "\n",
    "    n_scores = target_scores.size + nontarget_scores.size # sum of sizes \n",
    "    all_scores = np.concatenate((target_scores, nontarget_scores)) # vector of scores\n",
    "    labels = np.concatenate((np.ones(target_scores.size), np.zeros(nontarget_scores.size))) # vextor of labels\n",
    "    # Sort labels based on scores\n",
    "    indices = np.argsort(all_scores, kind='mergesort') # retern indexes of sorted array of zeros and ones\n",
    "    labels = labels[indices] # and sort labels like (zeros and ones) for all 0 in both arrays and (zeros + ones) of 1 in both arrays\n",
    "\n",
    "    # Compute false rejection and false acceptance rates\n",
    "    tar_trial_sums = np.cumsum(labels) # array with max element N\n",
    "    # (np.arange(1, n_scores + 1, step = 1) - tar_trial_sums | gives array of element with max el = N\n",
    "    nontarget_trial_sums = nontarget_scores.size - (np.arange(1, n_scores + 1, step = 1) - tar_trial_sums)\n",
    "\n",
    "    frr = np.concatenate((np.atleast_1d(0), tar_trial_sums / target_scores.size))  # false rejection rates\n",
    "    far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums / nontarget_scores.size))  # false acceptance rates\n",
    "    thresholds = np.concatenate((np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))  # Thresholds are the sorted scores\n",
    "\n",
    "    return frr, far, thresholds\n",
    "def compute_eer(target_scores, nontarget_scores):\n",
    "    \"\"\" Returns equal error rate (EER) and the corresponding threshold. \"\"\"\n",
    "    frr, far, thresholds = compute_det_curve(target_scores, nontarget_scores)\n",
    "    abs_diffs = np.abs(frr - far)\n",
    "    min_index = np.argmin(abs_diffs) # return index of min element\n",
    "    eer = np.mean((frr[min_index], far[min_index]))\n",
    "    return eer, thresholds[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0d62b89c9f402d84149b35db83395b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11472 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(CFG.epochs):\n",
    "    print(f'Epoch: {epoch + 1} ')\n",
    "    train_loss_meter = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        # Move batch to device if device != 'cpu'\n",
    "        wav = batch[0].to(device)\n",
    "        #length = batch['length'].to(device)\n",
    "        label = batch[1].to(device)\n",
    "        label = label.reshape(len(label))\n",
    "        label = torch.tensor(label).long()\n",
    "        #print(f'label:{label}')\n",
    "        wav = wav.squeeze()\n",
    "        #mel, mel_length = featurizer(wav, length)\n",
    "        output = model(wav)\n",
    "        #print(output)\n",
    "        #print(f'output :{output.argmax(dim=-1)}')\n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss_meter.update(loss.item())\n",
    "        \n",
    "    storage['train_loss'].append(train_loss_meter.avg)\n",
    "###################################################################################################################\n",
    "#############################################  Validation  ########################################################\n",
    "###################################################################################################################\n",
    "\n",
    "    validation_loss_meter = AverageMeter()\n",
    "    validation_accuracy_meter = AverageMeter()\n",
    "    validation_f1_meter = AverageMeter()\n",
    "    validation_EER_meter = AverageMeter()\n",
    "    #all_matrix = [[0,0],[0,0]]\n",
    "    model.eval()\n",
    "    for i, batch in enumerate(tqdm(valid_loader)):\n",
    "        # Move batch to device if device != 'cpu'\n",
    "        wav = batch[0].to(device)\n",
    "        #length = batch['length'].to(device)\n",
    "        label = batch[1].to(device)\n",
    "        label = label.reshape(len(label))\n",
    "        label = torch.tensor(label).long()\n",
    "        wav = wav.squeeze()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            #mel, mel_length = featurizer(wav, length)\n",
    "            output = model(wav)\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "            out = output.argmax(dim=-1).cpu().numpy()\n",
    "            labels = label.cpu().numpy()\n",
    "        #print(f'output :{output.argmax(dim=-1)}, label : {label}')\n",
    "        matches = (output.argmax(dim=-1) == label).float().mean()\n",
    "\n",
    "        validation_loss_meter.update(loss.item())\n",
    "        validation_accuracy_meter.update(matches.item())\n",
    "        f1 = f1_score(output.argmax(dim=-1).cpu(), label.cpu(), average= 'weighted')\n",
    "        eer = compute_eer(labels,out)\n",
    "        validation_EER_meter.update(eer[0])\n",
    "        validation_f1_meter.update(f1)\n",
    "        #matrix = confusion_matrix(labels,out)\n",
    "        #all_matrix+=matrix\n",
    "        print(f'F1 :{f1} , EER: {eer}')\n",
    "        #print(f'Confusion Matrix of all:{all_matrix}')\n",
    "    storage['validation_loss'].append(validation_loss_meter.avg)\n",
    "    storage['validation_accuracy'].append(validation_accuracy_meter.avg)\n",
    "    storage['validation_F1_score'].append(validation_f1_meter.avg)\n",
    "    storage['validation_EER'].append(validation_EER_meter.avg)\n",
    "    display.clear_output()\n",
    "    #print(f'Confusion Matrix of all:{all_matrix}')\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "\n",
    "    axes[0].plot(storage['train_loss'], label='train_loss')\n",
    "    axes[1].plot(storage['validation_loss'], label='validation_loss')\n",
    "    \n",
    "    axes[2].plot(storage['validation_accuracy'], label='validation_accuracy')\n",
    "    axes[3].plot(storage['validation_F1_score'], label='validation_F1_score')\n",
    "    axes[4].plot(storage['validation_EER'], label='EER')\n",
    "    for i in range(5):\n",
    "        axes[i].grid()\n",
    "        axes[i].legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "PATH = f\"./result/ebest_epoch_ofeffnet_b1.bin\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrix = [[0,0],[0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrix+=matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage['validation_F1_score']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(out.cpu(),label.cpu(),average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:11:13.108463Z",
     "iopub.status.busy": "2022-07-13T22:11:13.107767Z",
     "iopub.status.idle": "2022-07-13T22:27:41.170460Z",
     "shell.execute_reply": "2022-07-13T22:27:41.169446Z",
     "shell.execute_reply.started": "2022-07-13T22:11:13.108421Z"
    }
   },
   "outputs": [],
   "source": [
    "#fit(model, CFG.epochs , train_loader, valid_loader, optimizer, CFG.criterion, CFG.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficcient_net predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:27:41.922371Z",
     "iopub.status.busy": "2022-07-13T22:27:41.921713Z",
     "iopub.status.idle": "2022-07-13T22:27:45.531639Z",
     "shell.execute_reply": "2022-07-13T22:27:45.530687Z",
     "shell.execute_reply.started": "2022-07-13T22:27:41.922318Z"
    }
   },
   "outputs": [],
   "source": [
    "#test = []\n",
    "'./test/'\n",
    "items_names= [item_name.split('.')[0] for item_name in os.listdir(CFG.test_path)]#os.path.join(\"./test\",item_name)\n",
    "test_dataset = UrbanSoundDataset(data, items_names, mel_spectrogram, CFG.SAMPLE_RATE, CFG.NUM_SAMPLES, False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, num_workers=0, shuffle=False, pin_memory=True, drop_last=False,collate_fn=Collator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i, batch in enumerate(tqdm(test_loader)):\n",
    "        # Move batch to device if device != 'cpu'\n",
    "        wav = batch['wav'].to(device)\n",
    "        length = batch['length'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            mel, mel_length = featurizer(wav, length)\n",
    "            output = model(mel, mel_length)\n",
    "            #print(output)\n",
    "            _, pred = torch.max(output, 1) # Return values and indices\n",
    "            #m = nn.Softmax(dim=1)\n",
    "            #pred = m(output)\n",
    "            #print(pred)\n",
    "            #print(pred.item())\n",
    "            #df\n",
    "            test.append(classes[pred.item()])\n",
    "#print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_names= [item_name.split('.')[0] for item_name in os.listdir(CFG.test_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:29:38.581683Z",
     "iopub.status.busy": "2022-07-13T22:29:38.581326Z",
     "iopub.status.idle": "2022-07-13T22:29:38.588448Z",
     "shell.execute_reply": "2022-07-13T22:29:38.585882Z",
     "shell.execute_reply.started": "2022-07-13T22:29:38.581655Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"id\" :items_names,\n",
    "                   \"eff\": test\n",
    "        \n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.747598Z",
     "iopub.status.idle": "2022-07-13T22:27:45.748300Z",
     "shell.execute_reply": "2022-07-13T22:27:45.748059Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.748035Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ansamble_pred = df['eff'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generating submission file...')\n",
    "#os.chdir(\"./\")\n",
    "df.to_csv('answers.tsv',index=False, sep = '\\t',header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.749586Z",
     "iopub.status.idle": "2022-07-13T22:27:45.750270Z",
     "shell.execute_reply": "2022-07-13T22:27:45.750041Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.750017Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\"id\" : range(1,250),\n",
    "#                    \"class\": ansamble_pred\n",
    "# #                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.751572Z",
     "iopub.status.idle": "2022-07-13T22:27:45.752256Z",
     "shell.execute_reply": "2022-07-13T22:27:45.752029Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.752006Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\"id\" : range(1,250),\n",
    "#                    \"class\": test\n",
    "#                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.754037Z",
     "iopub.status.idle": "2022-07-13T22:27:45.754749Z",
     "shell.execute_reply": "2022-07-13T22:27:45.754517Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.754493Z"
    }
   },
   "outputs": [],
   "source": [
    "# df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.756008Z",
     "iopub.status.idle": "2022-07-13T22:27:45.756719Z",
     "shell.execute_reply": "2022-07-13T22:27:45.756489Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.756465Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.757997Z",
     "iopub.status.idle": "2022-07-13T22:27:45.758717Z",
     "shell.execute_reply": "2022-07-13T22:27:45.758484Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.758460Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_full.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.760001Z",
     "iopub.status.idle": "2022-07-13T22:27:45.760725Z",
     "shell.execute_reply": "2022-07-13T22:27:45.760495Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.760471Z"
    }
   },
   "outputs": [],
   "source": [
    "# print('Generating submission file...')\n",
    "#os.chdir(\"./\")\n",
    "# df.to_csv('submission_audio.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-13T22:27:45.761988Z",
     "iopub.status.idle": "2022-07-13T22:27:45.762720Z",
     "shell.execute_reply": "2022-07-13T22:27:45.762480Z",
     "shell.execute_reply.started": "2022-07-13T22:27:45.762456Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_full.to_csv('submission_effnet7new2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
